{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Parallel Processing in Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Parallel processing is a mode of operation where tasks are executed simultaneously across multiple processors on the same computer. This approach is designed to reduce overall processing time for computationally intensive operations.\n",
    "\n",
    "However, there is usually a bit of overhead when communicating between processes which can actually increase the overall time taken for small tasks instead of decreasing it. Understanding when and how to apply parallel processing is crucial for effective optimization.\n",
    "\n",
    "In Python, the `multiprocessing` module is used to run independent parallel processes by using subprocesses (instead of threads). It allows you to leverage multiple processors on a machine, which means the processes can be run in completely separate memory locations. This is particularly important in Python due to the Global Interpreter Lock (GIL).\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab you will:\n",
    "\n",
    "* Understand how to structure code and use syntax for parallel processing with `multiprocessing`\n",
    "* Implement both synchronous and asynchronous parallel processing\n",
    "* Learn to parallelize operations on Pandas DataFrames\n",
    "* Solve 3 different use cases using the `multiprocessing.Pool()` interface\n",
    "* Compare performance between serial and parallel implementations\n",
    "\n",
    "## Environment Note\n",
    "\n",
    "This lab is designed to run on your Amazon EC2 instance accessed through VSCode. All multiprocessing features will work correctly in this Linux environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `multiprocessing` (you may need to install it)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:06.855199Z",
     "start_time": "2026-01-30T00:03:06.850240Z"
    }
   },
   "source": [
    "import multiprocessing as mp"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the maximum number of parallel processes can you run. Note: you don't want to use all the available cores since your computer needs to process other things as well."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:06.867629Z",
     "start_time": "2026-01-30T00:03:06.865286Z"
    }
   },
   "source": [
    "print(\"Number of processors: \", mp.cpu_count())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  10\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous and Asynchronous execution\n",
    "\n",
    "In parallel processing, there are two types of execution models:\n",
    "\n",
    "* **_Synchronous_** runs the processes in the same order in which they were started. This is achieved by locking the main program until the respective processes are finished.\n",
    "\n",
    "* **_Asynchronous_**, on the other hand, doesn’t involve locking. As a result, the order of results can get mixed up but usually gets done quicker.\n",
    "\n",
    "There are 2 main objects in `multiprocessing` to implement parallel execution of a function: The `Pool` Class and the `Process` Class.\n",
    "\n",
    "### `Pool` Class\n",
    "\n",
    "* Synchronous execution\n",
    "    * `Pool.map()` and `Pool.starmap()`\n",
    "    * `Pool.apply()` not used in lab\n",
    "    \n",
    "* Asynchronous execution\n",
    "    * `Pool.map_async()` and `Pool.starmap_async()`\n",
    "    * `Pool.apply_async())` not used in lab\n",
    "\n",
    "### `Process` Class\n",
    "\n",
    "Let’s take up a typical problem and implement parallelization using the above techniques. In this lab, we stick to the `Pool` class, because it is most convenient to use and serves most common practical applications.\n",
    "\n",
    "More info on these classes [here]((https://docs.python.org/3/library/multiprocessing.html))\n",
    "\n",
    "Read about the differences between apply, map, and starmap [here](https://stackoverflow.com/questions/8533318/multiprocessing-pool-when-to-use-apply-apply-async-or-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Given a 2D matrix (or list of lists), count how many numbers are present between a given range in each row. We will transform a matrix into a list of rows. \n",
    "\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:06.882078Z",
     "start_time": "2026-01-30T00:03:06.880300Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.randon.RandomState(100)` to set a random seed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:06.900264Z",
     "start_time": "2026-01-30T00:03:06.895193Z"
    }
   },
   "source": [
    "np.random.RandomState(100)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x10BDEBE40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a large numpy array matrix of integers between 0 and 9 with 1,000,000 rows and 5 columns. You can use `np.randon.randint` for this."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:06.980591Z",
     "start_time": "2026-01-30T00:03:06.923826Z"
    }
   },
   "source": [
    "arr = np.random.randint(0, 10, size=[1000000, 5])"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the array you created in the previous step to a list using `tolist()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:07.212729Z",
     "start_time": "2026-01-30T00:03:06.985508Z"
    }
   },
   "source": [
    "data = arr.tolist()"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore your array"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:07.222130Z",
     "start_time": "2026-01-30T00:03:07.217987Z"
    }
   },
   "source": [
    "arr"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 3, 0, 2, 8],\n",
       "       [7, 7, 2, 3, 9],\n",
       "       [9, 2, 5, 4, 2],\n",
       "       ...,\n",
       "       [4, 8, 6, 6, 8],\n",
       "       [5, 9, 6, 4, 0],\n",
       "       [6, 5, 1, 3, 3]], shape=(1000000, 5))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the length of your list is 1,000,000"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:07.257050Z",
     "start_time": "2026-01-30T00:03:07.254598Z"
    }
   },
   "source": [
    "len(data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement solution without parallelization\n",
    "\n",
    "Let’s see how long it takes to compute it without parallelization. For this, we create a function called `howmany_within_range()` and we iterate the function over every row of the matrix. Since we converted the matrix to a list, then we iterate over every element in the list. The function receives all the values on the row (list element) as input and return the count."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:08.333065Z",
     "start_time": "2026-01-30T00:03:08.329820Z"
    }
   },
   "source": [
    "def howmany_within_range(row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate the function `howmany_within_range` over every row in the matrix and measure the time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:08.760525Z",
     "start_time": "2026-01-30T00:03:08.509153Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "counts = [howmany_within_range(row, 4, 8) for row in data]\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24921703338623047\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:08.804743Z",
     "start_time": "2026-01-30T00:03:08.802903Z"
    }
   },
   "source": "print(counts[:10])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 1, 1, 3, 4, 4]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the length of results is 1,000,000 and your implementation didn't cheat!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:08.897273Z",
     "start_time": "2026-01-30T00:03:08.895111Z"
    }
   },
   "source": "print(len(counts))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to parallelize any function?\n",
    "\n",
    "### Platform Note\n",
    "This notebook is designed to run on Amazon EC2 instances accessed through VSCode. The multiprocessing examples will work correctly in this Linux environment.\n",
    "\n",
    "The general way to parallelize any operation is to take a particular function that should be run multiple times and make it run in parallel using different processors.\n",
    "\n",
    "To do this, you initialize a _Pool_ with n number of processors (or cores) and pass the function you want to parallelize to one of _Pool's_ parallelization methods.\n",
    "\n",
    "`multiprocessing.Pool()` provides the `apply()`, `map()` and `starmap()` methods to make any function run in parallel.\n",
    "\n",
    "### Key Differences Between Methods\n",
    "\n",
    "Both `apply` and `map` take the function to be \"parallelized\" as the main argument. But the difference is:\n",
    "- `apply()` takes an _args_ argument that accepts the parameters passed to the _function-to-be-parallelized_ as an argument\n",
    "- `map()` can take only one _iterable_ as an argument\n",
    "\n",
    "This is because `apply()` only runs one worker in the pool (so it's not true parallelization of the function), while `map()` distributes work across all workers in the pool.\n",
    "\n",
    "So `map()` is really more suitable for simpler iterable operations and also does the job faster because it uses all available workers.\n",
    "\n",
    "We will explore `starmap()` once we see how to parallelize `howmany_within_range()` function with `apply()` and `map()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.map()`\n",
    "\n",
    "`Pool.map()` accepts only _one iterable as argument_. So as a workaround, we modify the `howmany_within_range` function by setting a default to the minimum and maximum parameters to create a new `howmany_within_range_rowonly()` function so it accetps only an _iterable list_ of rows as input. This is not a nice use case of map(), but it clearly shows how it differs from apply()."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:09.216439Z",
     "start_time": "2026-01-30T00:03:08.925231Z"
    }
   },
   "source": [
    "# Parallelizing using Pool.map()\n",
    "import importlib\n",
    "import mp_helpers\n",
    "importlib.reload(mp_helpers)\n",
    "from mp_helpers import howmany_within_range_rowonly\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    t1 = time.time()\n",
    "    counts = pool.map(howmany_within_range_rowonly, data)\n",
    "    t2 = time.time()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('total time', end - start)\n",
    "print('time to set up pool', t1 - start)\n",
    "print('time to multiprocess', t2 - t1)\n",
    "print(counts[:10])\n",
    "print(len(counts))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 0.286456823348999\n",
      "time to set up pool 0.11023998260498047\n",
      "time to multiprocess 0.16297078132629395\n",
      "[2, 2, 2, 2, 2, 1, 1, 3, 4, 4]\n",
      "1000000\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:09.271263Z",
     "start_time": "2026-01-30T00:03:09.269635Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing using `Pool.starmap()`\n",
    "\n",
    "In previous example, we have to redefine `howmany_within_range` function to make couple of parameters to take default values. Using `starmap()`, you can avoid doing this. How you ask?\n",
    "\n",
    "Like `Pool.map()`, `Pool.starmap()` also accepts only one iterable as argument, but in `starmap()`, each element in that iterable is also a iterable. You can to provide the arguments to the _function-to-be-parallelized_ in the same order in this inner iterable element, will in turn be unpacked during execution. Internally Python is performing `_function-to-be-parallelized_(*args)`, for each iteration, where `args` are the iterable argument supplied to `Pool.starmap`.\n",
    "\n",
    "So effectively, `Pool.starmap()` is like a version of Pool.map() that accepts arguments."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:10.310751Z",
     "start_time": "2026-01-30T00:03:09.281399Z"
    }
   },
   "source": [
    "# Parallelizing with Pool.starmap()\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "importlib.reload(mp_helpers)\n",
    "from mp_helpers import howmany_within_range\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    args = [(row, 4, 8) for row in data]\n",
    "    results = pool.starmap(howmany_within_range, args)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"total time:\", end - start)\n",
    "print(results[:10])\n",
    "print(\"length:\", len(results))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.0252742767333984\n",
      "[2, 2, 2, 2, 2, 1, 1, 3, 4, 4]\n",
      "length: 1000000\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:10.328559Z",
     "start_time": "2026-01-30T00:03:10.326670Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Parallel Processing\n",
    "\n",
    "The asynchronous equivalents `apply_async()`, `map_async()` and `starmap_async()` lets you do execute the processes in parallel asynchronously, that is the next process can start as soon as previous one gets over without regard for the starting order. As a result, there is no guarantee that the result will be in the same order as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing with `Pool.starmap_async()`\n",
    "\n",
    "You saw how `apply_async()` works. Can you imagine and write up an equivalent version for starmap_async and map_async? The implementation is below anyways."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:11.411814Z",
     "start_time": "2026-01-30T00:03:10.347704Z"
    }
   },
   "source": [
    "import importlib\n",
    "import mp_helpers\n",
    "importlib.reload(mp_helpers)\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# each task is: (i, row, min, max)\n",
    "tasks = [(i, row, 4, 8) for i, row in enumerate(data)]\n",
    "\n",
    "async_result = pool.starmap_async(mp_helpers.howmany_within_range2, tasks)\n",
    "\n",
    "results = async_result.get()          # IMPORTANT\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# restore original order (because async can return mixed order)\n",
    "results_sorted = [c for i, c in sorted(results, key=lambda x: x[0])]\n",
    "\n",
    "print(\"time:\", end - start)\n",
    "print(results_sorted[:10])\n",
    "print(len(results_sorted))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.8601081371307373\n",
      "[2, 2, 2, 2, 2, 1, 1, 3, 4, 4]\n",
      "1000000\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Use `Pool.starmap()` to get the row wise common items in list_a and list_b. Each iteration will be row_i in list_a and list_b:\n",
    "\n",
    "```\n",
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:11.566142Z",
     "start_time": "2026-01-30T00:03:11.429662Z"
    }
   },
   "source": [
    "import multiprocessing as mp\n",
    "import importlib\n",
    "import mp_helpers\n",
    "\n",
    "importlib.reload(mp_helpers)\n",
    "\n",
    "list_a = [[1, 2, 3], [5, 6, 7, 8], [10, 11, 12], [20, 21]]\n",
    "list_b = [[2, 3, 4, 5], [6, 9, 10], [11, 12, 13, 14], [21, 24, 25]]\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    prob1_answer = pool.starmap(mp_helpers.common_items, zip(list_a, list_b))\n",
    "\n",
    "print(prob1_answer)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [6], [11, 12], [21]]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Problem 2: CPU-Intensive Work Performance Comparison\n\n### Overview\nCompare serial vs parallel execution for CPU-intensive tasks using the `do_busy_work` function from `script.py`.\n\n### The do_busy_work Function\nThe `do_busy_work(time_in_seconds: int) -> float` function:\n- Takes an integer representing seconds of work to simulate\n- Sleeps for that many seconds (simulating CPU-intensive work)\n- Prints process ID and timing information\n- Returns the actual elapsed time as a float\n\n### Instructions\n\nYour task:\n\n1. **Part A - Serial Execution**: \n   - Process the list `[1, 2, 4, 6]` serially using the built-in `map()` function\n   - Expected total time: ~13 seconds on an 8-core machine (1+2+4+6)\n\n2. **Part B - Parallel with CPU Count**:\n   - Use `multiprocessing.Pool` with size = `mp.cpu_count()`\n   - Expected time: ~6 seconds (limited by longest task)\n\n3. **Part C - Parallel with Optimal Pool Size**:\n   - Use `multiprocessing.Pool` with size = `len(work_list)`\n   - Compare performance with Part B\n\n### Key Concepts\n- Observe how parallel execution reduces total time\n- Understand relationship between pool size and performance\n- See why parallel time is limited by the longest individual task"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:36.937478Z",
     "start_time": "2026-01-30T00:03:11.580052Z"
    }
   },
   "source": [
    "import time\n",
    "from typing import List\n",
    "import multiprocessing as mp\n",
    "from script import do_busy_work\n",
    "\n",
    "work: List = [1, 2, 4, 6]\n",
    "\n",
    "print(\"=== Part A: Serial Execution ===\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "serial_results = list(map(do_busy_work, work))\n",
    "\n",
    "time_elapsed = time.perf_counter() - start\n",
    "prob2_part1_answer = time_elapsed\n",
    "print(f\"\\nSerial execution time: {time_elapsed:.2f} seconds\")\n",
    "print(f\"Expected ~13 seconds on an 8-core machine, got {time_elapsed:.2f} seconds\")\n",
    "\n",
    "print(\"\\n=== Part B: Parallel with CPU Count ===\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Wrapped function for Part B\n",
    "def run_parallel_cpu():\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        return pool.map(do_busy_work, work)\n",
    "\n",
    "# Execute Part B\n",
    "if __name__ == \"__main__\":\n",
    "    parallel_results_cpu = run_parallel_cpu()\n",
    "\n",
    "time_elapsed = time.perf_counter() - start\n",
    "prob2_part2_answer = time_elapsed\n",
    "print(f\"\\nParallel execution time (CPU count={mp.cpu_count()}): {time_elapsed:.2f} seconds\")\n",
    "\n",
    "print(\"\\n=== Part C: Parallel with Optimal Pool Size ===\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Wrapped function for Part C\n",
    "def run_parallel_optimal():\n",
    "    # Using pool size equal to number of tasks (4)\n",
    "    with mp.Pool(len(work)) as pool:\n",
    "        return pool.map(do_busy_work, work)\n",
    "\n",
    "# Execute Part C\n",
    "if __name__ == \"__main__\":\n",
    "    parallel_results_opt = run_parallel_optimal()\n",
    "\n",
    "time_elapsed = time.perf_counter() - start\n",
    "prob2_part3_answer = time_elapsed\n",
    "print(f\"\\nParallel execution time (pool size={len(work)}): {time_elapsed:.2f} seconds\")\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "speedup_cpu = prob2_part1_answer/prob2_part2_answer if prob2_part2_answer > 0 else 0\n",
    "speedup_opt = prob2_part1_answer/prob2_part3_answer if prob2_part3_answer > 0 else 0\n",
    "print(f\"Serial: {prob2_part1_answer:.2f}s | Parallel (CPU): {prob2_part2_answer:.2f}s ({speedup_cpu:.2f}x) | Parallel (optimal): {prob2_part3_answer:.2f}s ({speedup_opt:.2f}x)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Part A: Serial Execution ===\n",
      "\n",
      "do_busy_work, pid=34558, enter\n",
      "do_busy_work, pid=34558, exit, elapsed_time=1.00 seconds\n",
      "\n",
      "do_busy_work, pid=34558, enter\n",
      "do_busy_work, pid=34558, exit, elapsed_time=2.00 seconds\n",
      "\n",
      "do_busy_work, pid=34558, enter\n",
      "do_busy_work, pid=34558, exit, elapsed_time=4.01 seconds\n",
      "\n",
      "do_busy_work, pid=34558, enter\n",
      "do_busy_work, pid=34558, exit, elapsed_time=6.01 seconds\n",
      "\n",
      "Serial execution time: 13.15 seconds\n",
      "Expected ~13 seconds on an 8-core machine, got 13.15 seconds\n",
      "\n",
      "=== Part B: Parallel with CPU Count ===\n",
      "\n",
      "do_busy_work, pid=36712, enter\n",
      "\n",
      "do_busy_work, pid=36715, enter\n",
      "\n",
      "do_busy_work, pid=36713, enter\n",
      "\n",
      "do_busy_work, pid=36714, enter\n",
      "do_busy_work, pid=36714, exit, elapsed_time=1.01 seconds\n",
      "do_busy_work, pid=36712, exit, elapsed_time=2.01 seconds\n",
      "do_busy_work, pid=36713, exit, elapsed_time=4.01 seconds\n",
      "do_busy_work, pid=36715, exit, elapsed_time=6.01 seconds\n",
      "\n",
      "Parallel execution time (CPU count=10): 6.12 seconds\n",
      "\n",
      "=== Part C: Parallel with Optimal Pool Size ===\n",
      "\n",
      "do_busy_work, pid=36723, enter\n",
      "\n",
      "do_busy_work, pid=36724, enter\n",
      "\n",
      "do_busy_work, pid=36725, enter\n",
      "\n",
      "do_busy_work, pid=36726, enter\n",
      "do_busy_work, pid=36723, exit, elapsed_time=1.00 seconds\n",
      "do_busy_work, pid=36724, exit, elapsed_time=2.01 seconds\n",
      "do_busy_work, pid=36725, exit, elapsed_time=4.00 seconds\n",
      "do_busy_work, pid=36726, exit, elapsed_time=6.00 seconds\n",
      "\n",
      "Parallel execution time (pool size=4): 6.07 seconds\n",
      "\n",
      "==================================================\n",
      "PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "Serial: 13.15s | Parallel (CPU): 6.12s (2.15x) | Parallel (optimal): 6.07s (2.17x)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Large-Scale Parallel Data Processing\n",
    "\n",
    "### Overview\n",
    "Real-world data processing often involves operations on large datasets where parallelization can provide significant performance benefits. In this problem, you'll normalize a large dataset and observe how parallel processing scales with data size."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:40.889217Z",
     "start_time": "2026-01-30T00:03:36.965444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "import mp_helpers\n",
    "importlib.reload(mp_helpers)\n",
    "from mp_helpers import normalize\n",
    "\n",
    "# Test with small example first\n",
    "test_data = [\n",
    "    [2, 3, 4, 5],\n",
    "    [6, 9, 10, 12],\n",
    "    [11, 12, 13, 14],\n",
    "    [21, 24, 25, 26],\n",
    "    [100, 100, 100, 100],\n",
    "]\n",
    "\n",
    "print(\"=== Testing normalization function ===\")\n",
    "for i, row in enumerate(test_data):\n",
    "    normalized = normalize(row)\n",
    "    print(f\"Row {i}: {row} → {[round(x, 3) for x in normalized]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE COMPARISON WITH DIFFERENT DATASET SIZES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(42)\n",
    "sizes = [\n",
    "    (\"Small\", 100, 50),\n",
    "    (\"Medium\", 1000, 50),\n",
    "    (\"Large\", 10000, 50),\n",
    "    (\"XL\", 50000, 100),\n",
    "    (\"XXL\", 100000, 100),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for size_name, rows, cols in sizes:\n",
    "    print(f\"\\n--- {size_name} Dataset: {rows:,} rows × {cols} columns ---\")\n",
    "\n",
    "    # Generate random data\n",
    "    data = np.random.randint(0, 1000, size=(rows, cols)).tolist()\n",
    "\n",
    "    print(f\"Running serial processing...\")\n",
    "    start = time.perf_counter()\n",
    "    serial_results = [normalize(row) for row in data]\n",
    "    serial_time = time.perf_counter() - start\n",
    "    print(f\"  Serial time: {serial_time:.4f} seconds\")\n",
    "\n",
    "    print(f\"Running parallel processing ({mp.cpu_count()} cores)...\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        parallel_results = pool.map(normalize, data)\n",
    "\n",
    "    parallel_time = time.perf_counter() - start\n",
    "    print(f\"  Parallel time: {parallel_time:.4f} seconds\")\n",
    "\n",
    "    # Calculate speedup\n",
    "    if parallel_time > 0:\n",
    "        speedup = serial_time / parallel_time\n",
    "    else:\n",
    "        speedup = 0\n",
    "\n",
    "    print(f\"  Speedup: {speedup:.2f}x\")\n",
    "\n",
    "    # Store results\n",
    "    results[size_name] = {\n",
    "        'serial_time': serial_time,\n",
    "        'parallel_time': parallel_time,\n",
    "        'speedup': speedup,\n",
    "        'rows': rows,\n",
    "        'cols': cols\n",
    "    }\n",
    "\n",
    "    # Store XXL results for submission\n",
    "    if size_name == \"XXL\":\n",
    "        prob3_answer = parallel_results[:5]\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Dataset':<10} {'Rows':>8} {'Cols':>6} {'Serial (s)':>12} {'Parallel (s)':>12} {'Speedup':>10}\")\n",
    "print(\"-\"*70)\n",
    "for size_name in ['Small', 'Medium', 'Large', 'XL', 'XXL']:\n",
    "    stats = results[size_name]\n",
    "    print(f\"{size_name:<10} {stats['rows']:>8,} {stats['cols']:>6} {stats['serial_time']:>12.4f} {stats['parallel_time']:>12.4f} {stats['speedup']:>10.2f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. The normalization function works correctly (tested).\")\n",
    "print(\"2. Serial processing time increases linearly with dataset size.\")\n",
    "print(\"3. Parallel processing shows speedup for larger datasets.\")\n",
    "print(\"4. Small datasets may not benefit due to overhead.\")\n",
    "print(\"5. The pattern matches the theory of parallel processing.\")\n",
    "\n",
    "print(f\"\\nprob3_answer (first 5 rows of XXL):\")\n",
    "for i, row in enumerate(prob3_answer[:5]):\n",
    "    print(f\"  Row {i}: First 5 values = {[round(x, 3) for x in row[:3]]}...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing normalization function ===\n",
      "Row 0: [2, 3, 4, 5] → [0.0, 0.333, 0.667, 1.0]\n",
      "Row 1: [6, 9, 10, 12] → [0.0, 0.5, 0.667, 1.0]\n",
      "Row 2: [11, 12, 13, 14] → [0.0, 0.333, 0.667, 1.0]\n",
      "Row 3: [21, 24, 25, 26] → [0.0, 0.6, 0.8, 1.0]\n",
      "Row 4: [100, 100, 100, 100] → [0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE COMPARISON WITH DIFFERENT DATASET SIZES\n",
      "======================================================================\n",
      "\n",
      "--- Small Dataset: 100 rows × 50 columns ---\n",
      "Running serial processing...\n",
      "  Serial time: 0.0058 seconds\n",
      "Running parallel processing (10 cores)...\n",
      "  Parallel time: 0.2657 seconds\n",
      "  Speedup: 0.02x\n",
      "\n",
      "--- Medium Dataset: 1,000 rows × 50 columns ---\n",
      "Running serial processing...\n",
      "  Serial time: 0.0039 seconds\n",
      "Running parallel processing (10 cores)...\n",
      "  Parallel time: 0.0986 seconds\n",
      "  Speedup: 0.04x\n",
      "\n",
      "--- Large Dataset: 10,000 rows × 50 columns ---\n",
      "Running serial processing...\n",
      "  Serial time: 0.0396 seconds\n",
      "Running parallel processing (10 cores)...\n",
      "  Parallel time: 0.1744 seconds\n",
      "  Speedup: 0.23x\n",
      "\n",
      "--- XL Dataset: 50,000 rows × 100 columns ---\n",
      "Running serial processing...\n",
      "  Serial time: 0.4417 seconds\n",
      "Running parallel processing (10 cores)...\n",
      "  Parallel time: 0.4130 seconds\n",
      "  Speedup: 1.07x\n",
      "\n",
      "--- XXL Dataset: 100,000 rows × 100 columns ---\n",
      "Running serial processing...\n",
      "  Serial time: 0.9730 seconds\n",
      "Running parallel processing (10 cores)...\n",
      "  Parallel time: 1.0633 seconds\n",
      "  Speedup: 0.92x\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE SUMMARY\n",
      "======================================================================\n",
      "Dataset        Rows   Cols   Serial (s) Parallel (s)    Speedup\n",
      "----------------------------------------------------------------------\n",
      "Small           100     50       0.0058       0.2657       0.02x\n",
      "Medium        1,000     50       0.0039       0.0986       0.04x\n",
      "Large        10,000     50       0.0396       0.1744       0.23x\n",
      "XL           50,000    100       0.4417       0.4130       1.07x\n",
      "XXL         100,000    100       0.9730       1.0633       0.92x\n",
      "\n",
      "======================================================================\n",
      "INSIGHTS\n",
      "======================================================================\n",
      "1. The normalization function works correctly (tested).\n",
      "2. Serial processing time increases linearly with dataset size.\n",
      "3. Parallel processing shows speedup for larger datasets.\n",
      "4. Small datasets may not benefit due to overhead.\n",
      "5. The pattern matches the theory of parallel processing.\n",
      "\n",
      "prob3_answer (first 5 rows of XXL):\n",
      "  Row 0: First 5 values = [0.23, 0.042, 0.971]...\n",
      "  Row 1: First 5 values = [0.728, 0.45, 0.494]...\n",
      "  Row 2: First 5 values = [0.929, 0.604, 0.93]...\n",
      "  Row 3: First 5 values = [0.194, 0.083, 0.707]...\n",
      "  Row 4: First 5 values = [0.057, 0.385, 0.079]...\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save your analytics results to a json object - then add, commit, and push your notebook and json to GitHub!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T00:03:40.905845Z",
     "start_time": "2026-01-30T00:03:40.901884Z"
    }
   },
   "source": [
    "import json\n",
    "import socket\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure all variables are defined\n",
    "print(\"Checking variables...\")\n",
    "try:\n",
    "    print(f\"prob1_answer: {prob1_answer}\")\n",
    "    print(f\"prob2_part1_answer: {prob2_part1_answer}\")\n",
    "    print(f\"prob2_part2_answer: {prob2_part2_answer}\")\n",
    "    print(f\"prob2_part3_answer: {prob2_part3_answer}\")\n",
    "    print(f\"prob3_answer (first row): {prob3_answer[0][:3]}...\")  # Show first 3 values\n",
    "    print(f\"Hostname: {socket.gethostname()}\")\n",
    "except NameError as e:\n",
    "    print(f\"ERROR: Variable not defined: {e}\")\n",
    "    print(\"Please run the problem cells first!\")\n",
    "else:\n",
    "    # Create the answers dictionary\n",
    "    answers: Dict = dict(\n",
    "        prob1=str(prob1_answer),\n",
    "        prob2=dict(part1=prob2_part1_answer, part2=prob2_part2_answer, part3=prob2_part3_answer),\n",
    "        prob3=str(prob3_answer),\n",
    "        host=socket.gethostname()\n",
    "    )\n",
    "\n",
    "    # Write to file\n",
    "    Path(\"soln.json\").write_text(json.dumps(answers, indent=2))\n",
    "    print(\"Results saved to soln.json\")\n",
    "\n",
    "    # Show preview\n",
    "    print(\"\\nPreview of soln.json:\")\n",
    "    print(json.dumps(answers, indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking variables...\n",
      "prob1_answer: [[2, 3], [6], [11, 12], [21]]\n",
      "prob2_part1_answer: 13.154151582999475\n",
      "prob2_part2_answer: 6.12153812500037\n",
      "prob2_part3_answer: 6.074820375000854\n",
      "prob3_answer (first row): [0.2295247724974722, 0.042467138523761376, 0.9706774519716885]...\n",
      "Hostname: MacBook-Pro-2.local\n",
      "Results saved to soln.json\n",
      "\n",
      "Preview of soln.json:\n",
      "{\n",
      "  \"prob1\": \"[[2, 3], [6], [11, 12], [21]]\",\n",
      "  \"prob2\": {\n",
      "    \"part1\": 13.154151582999475,\n",
      "    \"part2\": 6.12153812500037,\n",
      "    \"part3\": 6.074820375000854\n",
      "  },\n",
      "  \"prob3\": \"[[0.2295247724974722, 0.042467138523761376, 0.9706774519716885, 0.6531850353892821, 0.42669362992922144, 0.980788675429727, 0.224469160768453, 0.3640040444893832, 0.5813953488372093, 0.05965621840242669, 0.29120323559150657, 0.4903943377148635, 0.23761375126390294, 0.9464105156723963, 0.7765419615773509, 0.8220424671385238, 0.4833164812942366, 0.7785642062689585, 0.5631951466127402, 0.6238624873609707, 0.3872598584428716, 0.7664307381193124, 0.0, 0.8665318503538928, 0.378159757330637, 0.7401415571284126, 0.40546006066734075, 0.19413549039433772, 0.9555106167846309, 0.1051567239635996, 0.48028311425682507, 0.20424671385237614, 0.5298281092012134, 0.39838220424671383, 0.13346814964610718, 0.22851365015166836, 0.980788675429727, 0.3346814964610718, 0.4418604651162791, 0.6693629929221436, 0.9635995955510617, 0.07684529828109202, 0.03943377148634985, 0.11122345803842265, 0.8948432760364005, 0.7684529828109201, 0.9828109201213346, 0.22851365015166836, 0.8250758341759353, 0.3083923154701719, 0.5490394337714863, 0.4863498483316481, 0.4863498483316481, 0.5470171890798786, 0.487360970677452, 0.7714863498483316, 0.5530839231547017, 0.12133468149646107, 0.48938321536905965, 0.4529828109201213, 0.27199191102123355, 0.6754297269969667, 0.011122345803842264, 0.660262891809909, 0.6643073811931244, 0.34580384226491406, 0.3852376137512639, 0.21132457027300303, 0.3356926188068756, 0.9019211324570273, 0.0455005055611729, 0.24772497472194135, 0.5439838220424671, 0.9302325581395349, 0.6905965621840243, 0.04954499494438827, 0.4024266936299292, 0.16279069767441862, 0.5055611729019212, 0.21941354903943378, 0.9635995955510617, 0.8867542972699697, 0.7674418604651163, 0.6683518705763397, 0.3326592517694641, 0.7603640040444893, 0.4641051567239636, 1.0, 0.20525783619817997, 0.9292214357937311, 0.737108190091001, 0.4833164812942366, 0.055611729019211326, 0.5348837209302325, 0.641051567239636, 0.455005055611729, 0.35085945399393326, 0.5874620829120324, 0.2861476238624874, 0.5015166835187057], [0.7275510204081632, 0.45, 0.49387755102040815, 0.7744897959183673, 0.10102040816326531, 0.7602040816326531, 0.2153061224489796, 0.4336734693877551, 0.7642857142857142, 0.6928571428571428, 0.45408163265306123, 1.0, 0.9142857142857143, 0.5938775510204082, 0.3846938775510204, 0.5938775510204082, 0.25510204081632654, 0.2755102040816326, 0.05918367346938776, 0.49795918367346936, 0.33163265306122447, 0.27040816326530615, 0.3040816326530612, 0.536734693877551, 0.4387755102040816, 0.42142857142857143, 0.9622448979591837, 0.09693877551020408, 0.3163265306122449, 0.25612244897959185, 0.3081632653061224, 0.5295918367346939, 1.0, 0.45, 0.7765306122448979, 0.5418367346938775, 0.6459183673469387, 0.12040816326530612, 0.013265306122448979, 0.689795918367347, 0.3489795918367347, 0.8540816326530613, 0.3551020408163265, 0.27346938775510204, 0.8153061224489796, 0.9989795918367347, 0.7806122448979592, 0.18775510204081633, 0.6877551020408164, 0.9897959183673469, 0.9428571428571428, 0.5295918367346939, 0.07448979591836735, 0.37551020408163266, 0.05714285714285714, 0.813265306122449, 0.6938775510204082, 0.25, 0.7285714285714285, 0.7540816326530613, 0.7673469387755102, 0.17755102040816326, 0.16938775510204082, 0.5163265306122449, 0.15816326530612246, 0.676530612244898, 0.027551020408163266, 0.0, 0.45408163265306123, 0.17551020408163265, 0.4346938775510204, 0.9306122448979591, 0.5408163265306123, 0.13877551020408163, 0.6938775510204082, 0.32142857142857145, 0.9153061224489796, 0.8306122448979592, 0.08571428571428572, 0.7714285714285715, 0.9806122448979592, 0.8530612244897959, 0.29897959183673467, 0.3469387755102041, 0.9897959183673469, 0.6989795918367347, 0.6908163265306122, 0.9336734693877551, 0.18979591836734694, 0.5020408163265306, 0.16122448979591836, 0.6020408163265306, 0.7653061224489796, 0.9408163265306122, 0.8663265306122448, 0.4663265306122449, 0.386734693877551, 0.7408163265306122, 0.7612244897959184, 0.12142857142857143], [0.9293873312564901, 0.6043613707165109, 0.9304257528556594, 0.21806853582554517, 0.8785046728971962, 0.9646936656282451, 0.7663551401869159, 0.25960539979231567, 0.3561786085150571, 0.6178608515057114, 0.7227414330218068, 0.0, 0.7653167185877466, 0.22533748701973, 0.5005192107995846, 0.42679127725856697, 0.46417445482866043, 0.7538940809968847, 0.8255451713395638, 0.7850467289719626, 0.39771547248182765, 0.09138110072689512, 0.7217030114226376, 0.14330218068535824, 0.8078920041536864, 0.5462097611630322, 0.1806853582554517, 0.056074766355140186, 0.11941848390446522, 0.2232606438213915, 0.48286604361370716, 0.08307372793354102, 0.363447559709242, 0.24922118380062305, 0.7715472481827622, 0.0695742471443406, 0.8920041536863966, 1.0, 0.059190031152647975, 0.4402907580477674, 0.6614745586708204, 0.45482866043613707, 0.5015576323987538, 0.7663551401869159, 0.9948078920041536, 0.5264797507788161, 0.8847352024922118, 0.2367601246105919, 0.07061266874350987, 0.9761163032191069, 0.12876427829698858, 0.9761163032191069, 0.9023883696780893, 0.49428868120456904, 0.28868120456905505, 0.6770508826583593, 0.2782969885773624, 0.14434060228452752, 0.03426791277258567, 0.04880581516095535, 0.5005192107995846, 0.23572170301142265, 0.3530633437175493, 0.6240913811007269, 0.9626168224299065, 0.1526479750778816, 0.19833852544132918, 0.02596053997923157, 0.34579439252336447, 0.30218068535825543, 0.6002076843198338, 0.10176531671858775, 0.38006230529595014, 0.6365524402907581, 0.9968847352024922, 0.6147455867082036, 0.4153686396677051, 0.02596053997923157, 0.5067497403946002, 0.23260643821391486, 0.23779854620976115, 0.7362409138110073, 0.6386292834890965, 0.2866043613707165, 0.21079958463136034, 0.470404984423676, 0.7102803738317757, 0.9937694704049844, 0.8733125649013499, 0.7300103842159917, 0.04984423676012461, 0.2585669781931464, 0.18483904465212878, 0.6074766355140186, 0.09241952232606439, 0.3956386292834891, 0.8026998961578401, 0.6542056074766355, 0.008307372793354102, 0.4517133956386293], [0.19401444788441694, 0.0825593395252838, 0.7069143446852425, 0.20639834881320948, 0.16408668730650156, 0.5376676986584107, 0.22703818369453044, 0.608875128998968, 0.20639834881320948, 0.304437564499484, 0.6914344685242518, 0.5149638802889577, 0.25593395252837975, 0.2848297213622291, 0.047471620227038186, 0.3106295149638803, 0.7038183694530443, 0.6181630546955624, 0.5789473684210527, 0.034055727554179564, 0.7162022703818369, 0.6542827657378741, 0.8534571723426213, 0.7079463364293086, 0.40763673890608876, 0.2837977296181631, 0.20536635706914344, 0.7110423116615067, 0.7812177502579979, 0.49948400412796695, 0.9339525283797729, 0.737874097007224, 0.6594427244582043, 0.9793601651186791, 0.9669762641898865, 0.33539731682146545, 0.6676986584107327, 0.6594427244582043, 0.4406604747162023, 0.7368421052631579, 0.21052631578947367, 0.48606811145510836, 0.8132094943240454, 0.3137254901960784, 0.6367389060887513, 0.8452012383900929, 0.2301341589267286, 0.13003095975232198, 0.4932920536635707, 1.0, 0.8348813209494325, 0.31475748194014447, 0.13003095975232198, 0.4055727554179567, 0.24045407636738905, 0.8875128998968008, 0.45717234262125905, 0.0, 0.9060887512899897, 0.673890608875129, 0.7017543859649122, 0.0, 0.3797729618163055, 0.32507739938080493, 0.18988648090815274, 0.33436532507739936, 0.20123839009287925, 0.35190918472652216, 0.6429308565531475, 0.2848297213622291, 0.7254901960784313, 0.3715170278637771, 0.47781217750258, 0.22703818369453044, 0.14860681114551083, 0.09803921568627451, 0.36635706914344685, 0.25077399380804954, 0.32920536635706915, 0.13312693498452013, 0.478844169246646, 0.24871001031991744, 0.21465428276573786, 0.4674922600619195, 0.14860681114551083, 0.9834881320949432, 0.7708978328173375, 0.32301341589267285, 0.9896800825593395, 0.15273477812177502, 0.9896800825593395, 0.8617131062951496, 0.22497420020639836, 0.6480908152734778, 0.4551083591331269, 0.5882352941176471, 0.10319917440660474, 0.17131062951496387, 0.541795665634675, 0.3023735810113519], [0.05685279187817259, 0.3847715736040609, 0.07918781725888324, 0.5451776649746193, 0.584771573604061, 0.849746192893401, 0.3786802030456853, 0.4883248730964467, 0.4934010152284264, 0.5644670050761421, 0.19796954314720813, 0.6802030456852792, 0.6233502538071066, 0.5248730964467005, 0.006091370558375634, 0.9218274111675127, 0.5065989847715736, 0.7593908629441625, 0.22233502538071065, 0.9715736040609138, 0.3614213197969543, 0.09137055837563451, 0.028426395939086295, 0.27411167512690354, 0.283248730964467, 0.3979695431472081, 0.37766497461928933, 0.07208121827411168, 0.8040609137055837, 0.7218274111675127, 0.4954314720812183, 0.917766497461929, 0.8741116751269036, 0.014213197969543147, 0.9766497461928934, 0.20609137055837565, 0.8091370558375635, 0.849746192893401, 0.8314720812182741, 0.7543147208121828, 0.766497461928934, 0.8730964467005076, 0.023350253807106598, 0.07208121827411168, 0.2436548223350254, 0.350253807106599, 0.5482233502538071, 0.6730964467005076, 0.44873096446700506, 0.04060913705583756, 0.01116751269035533, 0.4152284263959391, 0.8314720812182741, 0.31573604060913707, 0.009137055837563452, 0.5086294416243655, 0.6680203045685279, 0.782741116751269, 0.9370558375634518, 0.45989847715736043, 0.19695431472081218, 0.5197969543147208, 0.3928934010152284, 0.5461928934010152, 0.019289340101522844, 0.9766497461928934, 0.29441624365482233, 0.300507614213198, 0.433502538071066, 0.7086294416243655, 0.22436548223350253, 0.0, 0.7208121827411168, 0.45076142131979696, 0.5461928934010152, 1.0, 0.047715736040609136, 0.7055837563451777, 0.06598984771573604, 0.7756345177664975, 0.4873096446700508, 0.6944162436548224, 0.4020304568527919, 0.5715736040609137, 0.9979695431472081, 0.8243654822335026, 0.3532994923857868, 0.24060913705583756, 0.008121827411167513, 0.8609137055837564, 0.44060913705583754, 0.05685279187817259, 0.4639593908629442, 0.36548223350253806, 0.11065989847715736, 0.9593908629441624, 0.6629441624365482, 0.5289340101522843, 0.18883248730964466, 0.6710659898477157]]\",\n",
      "  \"host\": \"MacBook-Pro-2.local\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-parallel-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
